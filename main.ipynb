{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.14% de 189 palavras, desconhecidas 7.94%\n",
      "sepanhaki\n",
      "aspenhaki\n",
      "sepanhaki\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "with open('Base/words-utf-8.txt', 'r', encoding='utf-8') as file:\n",
    "    artigos = file.read()\n",
    "\n",
    "# Separa as pontuações das palavras\n",
    "def separa_palavras(lista_artigos):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "lista_tokens = tknzr.tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "\n",
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada\n",
    "\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "\n",
    "# Inserindo as letras esquecidas na hora de digitar a palavra\n",
    "def insere_letras(fatias) :\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "#Em caso de digitar caracteres a mais na palavra\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "# Quando há a troca de alguma letra\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáàãâéèêíìóòõôúùûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "# No caso de inverter um caracter. Exemplo: Shireker (Certo: Shrieker)\n",
    "def inverte_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "# Separando os lados(direito e esquerdo) da palavra, para verficar onde faltou o caracter\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas += inverte_letra(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key = probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)\n",
    "frequencia.most_common(10)\n",
    "\n",
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada] / total_palavras\n",
    "\n",
    "# Função para avaliar a taxa de acertos do corretor\n",
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    with open(nome_arquivo, \"r\", encoding='utf-8') as f:\n",
    "        for linha in f:\n",
    "            palavras = linha.split()[:2]  # Pega apenas as duas primeiras palavras\n",
    "            if len(palavras) == 2:\n",
    "                correta, errada = palavras\n",
    "                lista_palavras_teste.append((correta, errada))\n",
    "            else:\n",
    "                print(f\"A linha '{linha.strip()}' não contém exatamente duas palavras.\")\n",
    "    return lista_palavras_teste\n",
    "\n",
    "lista_teste = cria_dados_teste(\"Base/palavras.txt\")\n",
    "\n",
    "palavra = \"lóiigica\"\n",
    "\n",
    "# Verificando se há dois erros, exemplo: Liius (Certo = Luís)\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "palavras_g = gerador_turbinado(gerador_palavras(palavra))\n",
    "vocabulario = set(lista_normalizada)\n",
    "\n",
    "# Diminuindo o numero de palavras geradas para encontrar a certa no gerador_turbinado\n",
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "novo_corretor(palavra)\n",
    "\n",
    "#Um corretor que esteja preparado para corrigir tanto palavras com uma letra de distância quanto palavras\n",
    "#  com duas letras de distância da palavra correta.\n",
    "def corretor_condicional(palavra):\n",
    "  palavras_geradas = gerador_palavras(palavra)\n",
    "  suposta_palavra_correta = max(palavras_geradas,key=probabilidade)\n",
    "  palavras_conhecidas=[]\n",
    "  if suposta_palavra_correta in vocabulario:\n",
    "    palavra_correta = suposta_palavra_correta\n",
    "  else:\n",
    "    palavras_geradas_aprimoradas = gerador_turbinado(palavras_geradas)\n",
    "    soma_palavras = set(palavras_geradas + palavras_geradas_aprimoradas)\n",
    "    for palavra in soma_palavras:\n",
    "      if palavra in vocabulario:\n",
    "          palavras_conhecidas.append(palavra)\n",
    "    try:\n",
    "      palavra_correta = max(palavras_conhecidas,key=probabilidade)\n",
    "    except:\n",
    "      palavra_correta = palavra\n",
    "  return palavra_correta\n",
    "\n",
    "#  Avaliando a taxa de acerto do corretor/novo_corretor\n",
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor_condicional(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou * 100 / numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida * 100 / numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecidas {taxa_desconhecida}%\")\n",
    "\n",
    "avaliador(lista_teste, vocabulario)\n",
    "\n",
    "palavra = \"spenhaki\"\n",
    "print(novo_corretor(palavra))\n",
    "print(corretor(palavra))\n",
    "print(corretor_condicional(palavra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
